{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>credit_risk_score</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>fraud_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>295</td>\n",
       "      <td>40</td>\n",
       "      <td>AC</td>\n",
       "      <td>CA</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>97</td>\n",
       "      <td>40</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>AA</td>\n",
       "      <td>CD</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>224</td>\n",
       "      <td>40</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>268</td>\n",
       "      <td>50</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.8</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>AD</td>\n",
       "      <td>CA</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0.6</td>\n",
       "      <td>95</td>\n",
       "      <td>40</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.1</td>\n",
       "      <td>196</td>\n",
       "      <td>20</td>\n",
       "      <td>AB</td>\n",
       "      <td>CA</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.2</td>\n",
       "      <td>61</td>\n",
       "      <td>30</td>\n",
       "      <td>AB</td>\n",
       "      <td>CB</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.1</td>\n",
       "      <td>143</td>\n",
       "      <td>20</td>\n",
       "      <td>AB</td>\n",
       "      <td>CB</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     income  credit_risk_score  customer_age payment_type employment_status  \\\n",
       "0       0.8                295            40           AC                CA   \n",
       "1       0.6                 97            40           AB                CA   \n",
       "2       0.2                 58            30           AA                CD   \n",
       "3       0.1                224            40           AB                CA   \n",
       "4       0.6                268            50           AB                CA   \n",
       "..      ...                ...           ...          ...               ...   \n",
       "745     0.8                141            20           AD                CA   \n",
       "746     0.6                 95            40           AB                CA   \n",
       "747     0.1                196            20           AB                CA   \n",
       "748     0.2                 61            30           AB                CB   \n",
       "749     0.1                143            20           AB                CB   \n",
       "\n",
       "     current_address_months_count  fraud_bool  \n",
       "0                              73           1  \n",
       "1                             136           1  \n",
       "2                              70           1  \n",
       "3                             131           1  \n",
       "4                             149           1  \n",
       "..                            ...         ...  \n",
       "745                            30           0  \n",
       "746                           245           0  \n",
       "747                             8           0  \n",
       "748                           383           0  \n",
       "749                            28           0  \n",
       "\n",
       "[750 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df=pd.read_csv('./Kaggle Data/train_df.csv')\n",
    "test_df =pd.read_csv('./Kaggle Data/test_df.csv')\n",
    "# Cek Directory jika tidak terbaca\n",
    "#import os\n",
    "#print(\"Current Working Directory:\", os.getcwd())\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>750.0</td>\n",
       "      <td>0.613600</td>\n",
       "      <td>0.288269</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_risk_score</th>\n",
       "      <td>750.0</td>\n",
       "      <td>152.924000</td>\n",
       "      <td>81.260141</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>148.5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_age</th>\n",
       "      <td>750.0</td>\n",
       "      <td>37.706667</td>\n",
       "      <td>12.838499</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_address_months_count</th>\n",
       "      <td>750.0</td>\n",
       "      <td>101.602667</td>\n",
       "      <td>92.003857</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraud_bool</th>\n",
       "      <td>750.0</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.500270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count        mean        std    min   25%  \\\n",
       "income                        750.0    0.613600   0.288269    0.1   0.4   \n",
       "credit_risk_score             750.0  152.924000  81.260141 -110.0  95.0   \n",
       "customer_age                  750.0   37.706667  12.838499   10.0  30.0   \n",
       "current_address_months_count  750.0  101.602667  92.003857   -1.0  33.0   \n",
       "fraud_bool                    750.0    0.508000   0.500270    0.0   0.0   \n",
       "\n",
       "                                50%    75%    max  \n",
       "income                          0.7    0.9    0.9  \n",
       "credit_risk_score             148.5  205.0  357.0  \n",
       "customer_age                   40.0   50.0   80.0  \n",
       "current_address_months_count   71.0  150.0  388.0  \n",
       "fraud_bool                      1.0    1.0    1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>750</td>\n",
       "      <td>4</td>\n",
       "      <td>AB</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <td>750</td>\n",
       "      <td>6</td>\n",
       "      <td>CA</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count unique top freq\n",
       "payment_type        750      4  AB  279\n",
       "employment_status   750      6  CA  572"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numerical_features_train = train_df.select_dtypes(include=[np.number])\n",
    "num_summary_stats_train = numerical_features_train.describe().T\n",
    "categorical_features_train = train_df.select_dtypes(include=[object])\n",
    "cat_summary_stats_train = categorical_features_train.describe().T\n",
    "print(\"Numerical Features Summary Statistics:\")\n",
    "display(num_summary_stats_train)\n",
    "print(\"Categorical Features Summary Statistics:\")\n",
    "display(cat_summary_stats_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Berdasarkan metadata yang diberikan -1 berarti missing value untuk \"current_address_months_count\", kita gunakan imputation median\n",
    "median_current_address = train_df['current_address_months_count'][train_df['current_address_months_count'] != -1].median()\n",
    "median_current_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "payment_type_map = {\n",
    "    'AA': 0.353846,\n",
    "    'AB': 0.485255,\n",
    "    'AC': 0.614198,\n",
    "    'AD': 0.472222\n",
    "}\n",
    "employment_status_map = {\n",
    "    'CA': 0.526868,\n",
    "    'CB': 0.333333,\n",
    "    'CC': 0.728814,\n",
    "    'CD': 0.266667,\n",
    "    'CE': 0.333333,\n",
    "    'CF': 0.181818\n",
    "}\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.payment_type_map = {}\n",
    "        self.employment_status_map = {}\n",
    "        self.means = {}\n",
    "        self.std_devs = {}\n",
    "\n",
    "    def fit(self, df):\n",
    "        # Label Encoding\n",
    "        self.payment_type_map = df['payment_type'].value_counts(normalize=True).to_dict()\n",
    "        self.employment_status_map = df['employment_status'].value_counts(normalize=True).to_dict()\n",
    "\n",
    "        # Hanya fitur numerik tertentu yang belum terscale akan di standardisasi\n",
    "        for feature in ['credit_risk_score', 'customer_age', 'current_address_months_count']:\n",
    "            self.means[feature] = df[feature].mean()\n",
    "            self.std_devs[feature] = df[feature].std()\n",
    "\n",
    "    def transform(self, df):\n",
    "        preprocessed_df = df.copy()\n",
    "\n",
    "        # Label Encoding\n",
    "        preprocessed_df['payment_type'] = preprocessed_df['payment_type'].map(self.payment_type_map).astype(float)\n",
    "        preprocessed_df['employment_status'] = preprocessed_df['employment_status'].map(self.employment_status_map).astype(float)\n",
    "\n",
    "        # Impute Missing Value\n",
    "        preprocessed_df['current_address_months_count'] = preprocessed_df['current_address_months_count'].replace(-1, 71)  # 71 merupakan nilai median\n",
    "\n",
    "        # Standard Scaling\n",
    "        for feature in ['credit_risk_score', 'customer_age', 'current_address_months_count']:\n",
    "            preprocessed_df[feature] = (preprocessed_df[feature] - self.means[feature]) / self.std_devs[feature]\n",
    "        return preprocessed_df\n",
    "\n",
    "    def fit_transform(self, df):\n",
    "        self.fit(df)\n",
    "        return self.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor()\n",
    "preprocessed_train_df = preprocessor.fit_transform(train_df)\n",
    "preprocessed_test_df = preprocessor.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessed_train_df.drop(columns=[\"fraud_bool\"]).values\n",
    "y_train = preprocessed_train_df[\"fraud_bool\"].values\n",
    "\n",
    "X_test = preprocessed_test_df.drop(columns=[\"fraud_bool\"]).values\n",
    "y_test = preprocessed_test_df[\"fraud_bool\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    def __init__(self, spread, centroids, debug=False):\n",
    "        self.spread = spread\n",
    "        self.centroids = np.array(centroids) \n",
    "        self.debug = debug\n",
    "        self.weights = None  \n",
    "        self.bias = 1 \n",
    "\n",
    "    def _basis_function(self, r):\n",
    "        \"\"\"Radial basis function: exp(-r^2 / (2 * spread^2))\"\"\"\n",
    "        return np.exp(-r ** 2 / (2 * self.spread ** 2))\n",
    "\n",
    "    def _format_matrix_html(self, matrix, title):\n",
    "        \"\"\"Format a matrix as an HTML table (for debugging purposes).\"\"\"\n",
    "        table_html = f\"<b>{title}:</b><br><table style='border:1px solid black;'>\"\n",
    "        for row in matrix:\n",
    "            table_html += \"<tr>\"\n",
    "            for val in row:\n",
    "                table_html += f\"<td style='border:1px solid black; padding:5px;'>{val:.4f}</td>\"\n",
    "            table_html += \"</tr>\"\n",
    "        table_html += \"</table><br>\"\n",
    "        return table_html\n",
    "\n",
    "    def _calculate_outputs(self, X):\n",
    "        \"\"\"Calculate the outputs of the hidden layer (RBF layer).\"\"\"\n",
    "        # Ensure the centroids match the input dimensionality\n",
    "        assert X.shape[1] == self.centroids.shape[1], f\"Input dimensionality ({X.shape[1]}) must match centroid dimensionality ({self.centroids.shape[1]})\"\n",
    "        \n",
    "        # Calculate distances from each input point to each centroid\n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)\n",
    "        if self.debug:\n",
    "            display(HTML(self._format_matrix_html(distances, \"Distances\")))\n",
    "        \n",
    "        # Apply the RBF function to the distances\n",
    "        outputs = self._basis_function(distances)\n",
    "        if self.debug:\n",
    "            display(HTML(self._format_matrix_html(outputs, \"RBF Outputs\")))\n",
    "        return outputs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the RBF network using the pseudo-inverse.\"\"\"\n",
    "        rbf_outputs = self._calculate_outputs(X)\n",
    "        y = y.reshape(-1, 1)\n",
    "        rbf_outputs = np.hstack((rbf_outputs, np.ones((rbf_outputs.shape[0], 1))))\n",
    "\n",
    "        # Calculate weights using pseudo-inverse\n",
    "        self.weights = np.linalg.pinv(rbf_outputs) @ y\n",
    "\n",
    "        if self.debug:\n",
    "            display(HTML(self._format_matrix_html(self.weights, \"Calculated Weights (including bias)\")))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the trained RBF network.\"\"\"\n",
    "        rbf_outputs = self._calculate_outputs(X)\n",
    "        rbf_outputs = np.hstack((rbf_outputs, np.ones((rbf_outputs.shape[0], 1))))  \n",
    "        return rbf_outputs @ self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "    def __init__(self, population_size, num_selection, mutation_rate, exposure_rate, max_iterations, seed, train_dataset, test_dataset, debug=True):\n",
    "        self.population_size = population_size\n",
    "        self.num_selection = num_selection\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.exposure_rate = exposure_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.dataset_X_train, self.dataset_y_train = train_dataset\n",
    "        self.dataset_X_test, self.dataset_y_test = test_dataset\n",
    "        self.population = []\n",
    "        np.random.seed(seed)\n",
    "        self.debug = debug \n",
    "        self.initialize_population()\n",
    "\n",
    "    def calculate_fitness(self):\n",
    "        fitness_test_values = []\n",
    "        fitness_train_values = []\n",
    "\n",
    "        for centroids, spread in self.population:\n",
    "            rbf = RBF(spread, centroids, debug=False)\n",
    "\n",
    "            # Fit the model on the training data\n",
    "            rbf.fit(self.dataset_X_train, self.dataset_y_train)\n",
    "\n",
    "            # Predictions on the training data\n",
    "            train_predictions = rbf.predict(self.dataset_X_train)\n",
    "            train_predicted_classes = (train_predictions >= 0.5).astype(int)\n",
    "            train_correct_predictions = sum(train_predicted_classes.flatten() == self.dataset_y_train)\n",
    "            train_accuracy = train_correct_predictions / len(self.dataset_y_train)\n",
    "\n",
    "            train_true_positive = sum((train_predicted_classes.flatten() == 1) & (self.dataset_y_train == 1))\n",
    "            train_false_positive = sum((train_predicted_classes.flatten() == 1) & (self.dataset_y_train == 0))\n",
    "            train_false_negative = sum((train_predicted_classes.flatten() == 0) & (self.dataset_y_train == 1))\n",
    "\n",
    "            train_precision = train_true_positive / (train_true_positive + train_false_positive) if (train_true_positive + train_false_positive) > 0 else 0\n",
    "            train_recall = train_true_positive / (train_true_positive + train_false_negative) if (train_true_positive + train_false_negative) > 0 else 0\n",
    "\n",
    "            train_f1_score = 2 * (train_precision * train_recall) / (train_precision + train_recall) if train_precision + train_recall > 0 else 0\n",
    "            fitness_train_values.append(train_f1_score)\n",
    "\n",
    "            # Predictions on the test data\n",
    "            test_predictions = rbf.predict(self.dataset_X_test)\n",
    "            test_predicted_classes = (test_predictions >= 0.5).astype(int)\n",
    "            test_correct_predictions = sum(test_predicted_classes.flatten() == self.dataset_y_test)\n",
    "            test_accuracy = test_correct_predictions / len(self.dataset_y_test)\n",
    "\n",
    "            test_true_positive = sum((test_predicted_classes.flatten() == 1) & (self.dataset_y_test == 1))\n",
    "            test_false_positive = sum((test_predicted_classes.flatten() == 1) & (self.dataset_y_test == 0))\n",
    "            test_false_negative = sum((test_predicted_classes.flatten() == 0) & (self.dataset_y_test == 1))\n",
    "\n",
    "            test_precision = test_true_positive / (test_true_positive + test_false_positive) if (test_true_positive + test_false_positive) > 0 else 0\n",
    "            test_recall = test_true_positive / (test_true_positive + test_false_negative) if (test_true_positive + test_false_negative) > 0 else 0\n",
    "\n",
    "            test_f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall) if test_precision + test_recall > 0 else 0\n",
    "            fitness_test_values.append(test_f1_score)\n",
    "\n",
    "        return fitness_train_values, fitness_test_values\n",
    "\n",
    "    def initialize_population(self):\n",
    "        dataset_X = self.dataset_X_train\n",
    "        for _ in range(self.population_size):\n",
    "            num_centroids = np.random.randint(24, 90)\n",
    "            centroids = self._generate_unique_centroids(dataset_X, num_centroids)\n",
    "            spread = np.random.uniform(0.01, 2)\n",
    "            self.population.append((centroids, spread))\n",
    "\n",
    "        # Debug output for initial population\n",
    "        if self.debug:\n",
    "            print(\"Initial Population:\")\n",
    "            for i, (centroids, spread) in enumerate(self.population):\n",
    "                print(f\"Individual {i + 1}: Number of Centroids={len(centroids)}, Spread={spread:.4f}\")\n",
    "\n",
    "    def _generate_unique_centroids(self, dataset_X, num_centroids):\n",
    "        \"\"\"Generate unique centroids by ensuring no duplicates.\"\"\"\n",
    "        indices = np.random.choice(dataset_X.shape[0], num_centroids, replace=False)\n",
    "        return dataset_X[indices]\n",
    "\n",
    "    def select(self, fitness_values):\n",
    "        total_fitness = sum(fitness_values)\n",
    "        selection_probabilities = [f / total_fitness for f in fitness_values]\n",
    "        cumulative_probabilities = np.cumsum(selection_probabilities)\n",
    "\n",
    "        selected_population = []\n",
    "        for _ in range(self.num_selection):\n",
    "            random_value = np.random.rand()\n",
    "            selected_index = np.searchsorted(cumulative_probabilities, random_value)\n",
    "            selected_population.append(self.population[selected_index])\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"Selected Population:\")\n",
    "            for i, (centroids, spread) in enumerate(selected_population):\n",
    "                print(f\"Selected Individual {i + 1}: Number of Centroids={len(centroids)}, Spread={spread:.4f}\")\n",
    "        return selected_population\n",
    "\n",
    "    def crossover(self, parent1, parent2):\n",
    "        x = np.random.uniform(0.2, 0.8)\n",
    "        centroids1, spread1 = parent1\n",
    "        centroids2, spread2 = parent2\n",
    "\n",
    "        num_centroids1 = centroids1.shape[0]\n",
    "        num_centroids2 = centroids2.shape[0]\n",
    "\n",
    "        # Child 1\n",
    "        num_child_centroids1_from_parent1 = round(x * num_centroids1)\n",
    "        num_child_centroids1_from_parent2 = round((1 - x) * num_centroids2)\n",
    "\n",
    "        selected_indices1 = np.random.choice(num_centroids1, num_child_centroids1_from_parent1, replace=False)\n",
    "        selected_centroids1 = centroids1[selected_indices1]\n",
    "        selected_indices2 = np.random.choice(num_centroids2, num_child_centroids1_from_parent2, replace=False)\n",
    "        selected_centroids2 = centroids2[selected_indices2]\n",
    "        child1_centroids = np.vstack((selected_centroids1, selected_centroids2))\n",
    "\n",
    "        # Child 2\n",
    "        num_child_centroids2_from_parent1 = round((1 - x) * num_centroids1)\n",
    "        num_child_centroids2_from_parent2 = round(x * num_centroids2)\n",
    "\n",
    "        selected_indices3 = np.random.choice(num_centroids1, num_child_centroids2_from_parent1, replace=False)\n",
    "        selected_centroids3 = centroids1[selected_indices3]\n",
    "        selected_indices4 = np.random.choice(num_centroids2, num_child_centroids2_from_parent2, replace=False)\n",
    "        selected_centroids4 = centroids2[selected_indices4]\n",
    "        child2_centroids = np.vstack((selected_centroids3, selected_centroids4))\n",
    "\n",
    "        # Ensure uniqueness in child centroids\n",
    "        child1_centroids = self._remove_duplicates(child1_centroids)\n",
    "        child2_centroids = self._remove_duplicates(child2_centroids)\n",
    "\n",
    "        if self.debug:\n",
    "            print(f\"Crossover: x={x:.4f}\")\n",
    "            print(f\"Parent 1: Number of Centroids={num_centroids1}\")\n",
    "            print(f\"Parent 2: Number of Centroids={num_centroids2}\")\n",
    "            print(f\"Child 1: Number of Centroids={len(child1_centroids)}\")\n",
    "            print(f\"Child 2: Number of Centroids={len(child2_centroids)}\")\n",
    "\n",
    "        return (child1_centroids, spread1), (child2_centroids, spread2)\n",
    "\n",
    "    def _remove_duplicates(self, centroids):\n",
    "        \"\"\"Remove duplicate centroids.\"\"\"\n",
    "        unique_centroids = np.unique(centroids, axis=0)\n",
    "        return unique_centroids[:max(1, len(centroids))]\n",
    "\n",
    "    def mutate(self, chromosome):\n",
    "        centroids, spread = chromosome\n",
    "        if np.random.rand() < self.exposure_rate:\n",
    "            # Original mutation on centroid values\n",
    "            for i in range(len(centroids)):\n",
    "                if np.random.rand() < self.mutation_rate:\n",
    "                    mutation_factor = np.random.uniform(-self.mutation_rate, self.mutation_rate)\n",
    "                    centroids[i] = centroids[i] * (1 + mutation_factor)\n",
    "\n",
    "            # Update spread within bounds\n",
    "            spread += np.random.uniform(-self.mutation_rate, self.mutation_rate)\n",
    "            spread = np.clip(spread, 0.1, 3)\n",
    "\n",
    "            # New mutation to modify the number of centroids\n",
    "            if np.random.rand() < self.mutation_rate:\n",
    "                # Calculate the percentage change in the number of centroids\n",
    "                change_percent = np.random.choice([2, 5]) * self.mutation_rate\n",
    "                target_centroids_count = max(1, round(len(centroids) * (1 + change_percent)))\n",
    "\n",
    "                if target_centroids_count > len(centroids):\n",
    "                    # Add new unique centroids if the target count is higher\n",
    "                    additional_centroids = self._generate_unique_centroids(self.dataset_X_train, target_centroids_count - len(centroids))\n",
    "                    centroids = np.vstack((centroids, additional_centroids))\n",
    "                elif target_centroids_count < len(centroids):\n",
    "                    # Remove random centroids if the target count is lower\n",
    "                    keep_indices = np.random.choice(len(centroids), target_centroids_count, replace=False)\n",
    "                    centroids = centroids[keep_indices]\n",
    "\n",
    "            # Ensure centroids remain unique after mutation\n",
    "            centroids = self._remove_duplicates(centroids)\n",
    "\n",
    "            if self.debug:\n",
    "                print(f\"Mutating: New Number of Centroids={len(centroids)}, Spread={spread:.4f}\")\n",
    "        return centroids, spread\n",
    "\n",
    "    def run(self):\n",
    "        best_train_fitness = 0\n",
    "        best_test_fitness = 0\n",
    "        best_accuracy_train = 0\n",
    "        best_accuracy_test = 0\n",
    "        best_parameters = None\n",
    "\n",
    "        for iteration in range(self.max_iterations):\n",
    "            fitness_train_values, fitness_test_values = self.calculate_fitness()\n",
    "            best_train_fitness = max(fitness_train_values)\n",
    "            best_test_fitness = max(fitness_test_values)\n",
    "\n",
    "            print(f\"Iteration {iteration + 1}, Best Fitness Train: {best_train_fitness}, Best Fitness Test: {best_test_fitness}\")\n",
    "\n",
    "            best_index = np.argmax(fitness_test_values)\n",
    "            best_centroids, best_spread = self.population[best_index]\n",
    "\n",
    "            rbf = RBF(best_spread, best_centroids, debug=False)\n",
    "            rbf.fit(self.dataset_X_train, self.dataset_y_train)\n",
    "\n",
    "            # Training accuracy\n",
    "            train_predictions = rbf.predict(self.dataset_X_train)\n",
    "            train_predicted_classes = (train_predictions >= 0.5).astype(int)\n",
    "            train_correct_predictions = sum(train_predicted_classes.flatten() == self.dataset_y_train)\n",
    "            accuracy_train = train_correct_predictions / len(self.dataset_y_train)\n",
    "\n",
    "            # Testing accuracy\n",
    "            test_predictions = rbf.predict(self.dataset_X_test)\n",
    "            test_predicted_classes = (test_predictions >= 0.5).astype(int)\n",
    "            test_correct_predictions = sum(test_predicted_classes.flatten() == self.dataset_y_test)\n",
    "            accuracy_test = test_correct_predictions / len(self.dataset_y_test)\n",
    "\n",
    "            print(f\"Iteration {iteration + 1}, Train Accuracy: {accuracy_train:.4f}, Test Accuracy: {accuracy_test:.4f}\")\n",
    "\n",
    "            if accuracy_test > best_accuracy_test:\n",
    "                best_accuracy_train = accuracy_train\n",
    "                best_accuracy_test = accuracy_test\n",
    "                best_parameters = {\n",
    "                    \"num_centroids\": len(best_centroids),\n",
    "                    \"spread\": best_spread\n",
    "                }\n",
    "\n",
    "            selected_population = self.select(fitness_test_values)\n",
    "            new_population = []\n",
    "\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1, parent2 = random.sample(selected_population, 2)\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                mutated_child1 = self.mutate(child1)\n",
    "                mutated_child2 = self.mutate(child2)\n",
    "                new_population.extend([mutated_child1, mutated_child2])\n",
    "\n",
    "            # Ensure the new population doesn't exceed population_size\n",
    "            self.population = new_population[:self.population_size]\n",
    "\n",
    "        print(f\"Best Train Accuracy: {best_accuracy_train:.4f}, Best Test Accuracy: {best_accuracy_test:.4f}\")\n",
    "        print(f\"Best Parameters: Number of Centroids = {best_parameters['num_centroids']}, Spread = {best_parameters['spread']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the Genetic Algorithm\n",
    "population_size = 500  # jumlah populasi awal\n",
    "num_selection = 250    # Jumalah seleksi populasi, rekomendasi 50% populasi awal\n",
    "mutation_rate = 0.4    # Probabilitas centroid mutasi\n",
    "exposure_rate = 0.25   # Probabilitas chromosome terkena mutasi\n",
    "max_iterations = 12     # Iterasi\n",
    "seed = 109          # Seed Random\n",
    "\n",
    "# Create an instance of the Genetic Algorithm\n",
    "ga = GeneticAlgorithm(\n",
    "    population_size=population_size,\n",
    "    num_selection=num_selection,\n",
    "    mutation_rate=mutation_rate,\n",
    "    exposure_rate=exposure_rate,\n",
    "    max_iterations=max_iterations,\n",
    "    seed=seed,\n",
    "    train_dataset=(X_train, y_train),\n",
    "    test_dataset=(X_test, y_test),\n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Best Fitness Train: 0.783641160949868, Best Fitness Test: 0.7983539094650206\n",
      "Iteration 1, Train Accuracy: 0.7707, Test Accuracy: 0.8040\n",
      "Iteration 2, Best Fitness Train: 0.8430609597924773, Best Fitness Test: 0.8083333333333333\n",
      "Iteration 2, Train Accuracy: 0.8387, Test Accuracy: 0.8160\n",
      "Iteration 3, Best Fitness Train: 0.9270833333333333, Best Fitness Test: 0.8898305084745762\n",
      "Iteration 3, Train Accuracy: 0.9253, Test Accuracy: 0.8960\n",
      "Iteration 4, Best Fitness Train: 0.9308996088657107, Best Fitness Test: 0.8870292887029289\n",
      "Iteration 4, Train Accuracy: 0.9293, Test Accuracy: 0.8920\n",
      "Iteration 5, Best Fitness Train: 0.9322916666666666, Best Fitness Test: 0.8823529411764706\n",
      "Iteration 5, Train Accuracy: 0.9307, Test Accuracy: 0.8880\n",
      "Iteration 6, Best Fitness Train: 0.9352331606217616, Best Fitness Test: 0.8786610878661087\n",
      "Iteration 6, Train Accuracy: 0.9333, Test Accuracy: 0.8840\n",
      "Iteration 7, Best Fitness Train: 0.9076723016905073, Best Fitness Test: 0.8464730290456433\n",
      "Iteration 7, Train Accuracy: 0.8973, Test Accuracy: 0.8520\n",
      "Iteration 8, Best Fitness Train: 1.0, Best Fitness Test: 0.9333333333333333\n",
      "Iteration 8, Train Accuracy: 0.9760, Test Accuracy: 0.9360\n",
      "Iteration 9, Best Fitness Train: 1.0, Best Fitness Test: 0.9121338912133891\n",
      "Iteration 9, Train Accuracy: 0.9587, Test Accuracy: 0.9160\n",
      "Iteration 10, Best Fitness Train: 0.9986859395532194, Best Fitness Test: 0.9243697478991597\n",
      "Iteration 10, Train Accuracy: 0.9440, Test Accuracy: 0.9280\n",
      "Best Train Accuracy: 0.9760, Best Test Accuracy: 0.9360\n",
      "Best Parameters: Number of Centroids = 635, Spread = 0.7218512211681043\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=109)\n",
    "ga.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
